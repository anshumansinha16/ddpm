{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install unet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8BpQ0clZOqO",
        "outputId": "cbcadf15-3055-491c-b6a1-cdb03644a4d9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting unet\n",
            "  Downloading unet-0.7.7-py2.py3-none-any.whl (8.1 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from unet) (2.0.0+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->unet) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->unet) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->unet) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->unet) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->unet) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->unet) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->unet) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->unet) (16.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->unet) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->unet) (1.3.0)\n",
            "Installing collected packages: unet\n",
            "Successfully installed unet-0.7.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from unet import UNet"
      ],
      "metadata": {
        "id": "gjcDdpclW5EG"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "w4ZTrWILD8mY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "f11bf9e3-bd40-461c-ce1c-1fb0d8bd85d2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nAt any arbitrary time-step we can write\\nx_t = sqrt(alpha_mean)*x0 + sqrt(1-alpha_mean)*epsilon\\n\\nmean = sqrt(a_hat_t)*x_0\\nvariance = sqrt(1-a_hat_t)*random_noise\\n\\nx_t = mean + variance\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "'''\n",
        "At any arbitrary time-step we can write\n",
        "x_t = sqrt(alpha_mean)*x0 + sqrt(1-alpha_mean)*epsilon\n",
        "\n",
        "mean = sqrt(a_hat_t)*x_0\n",
        "variance = sqrt(1-a_hat_t)*random_noise\n",
        "\n",
        "x_t = mean + variance\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Random input\n",
        "\n",
        "x0 = torch.randn(2,3,32,32) # batch, channel, imgximg\n",
        "x0 = torch.randn(2,10) # batch, #feats\n",
        "\n",
        "# Variance schedule (linear) , forward process.\n",
        "\n",
        "betas = torch.tensor([0.005, 0.1, 0.15, 0.2, 0.25])\n",
        "\n",
        "# Timestep (we want to take x_t at t = 1 and t = 3)\n",
        "# Timestep corrospond to the batch size ?\n",
        "\n",
        "t = torch.tensor([1,3])"
      ],
      "metadata": {
        "id": "CQqVzg2-HHIi"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# betas -> amounts of noise that are being applied at every timestep of the diffusion process.\n",
        "# alphas -> (1-betas) -> amount of original image's information that is being preserved. \n",
        "\n",
        "alphas = 1- betas\n",
        "alphas"
      ],
      "metadata": {
        "id": "wMDdXtF-HM22",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f9c6911-3562-4ca3-c73a-569e3636bc1b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.9950, 0.9000, 0.8500, 0.8000, 0.7500])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# cummalative product\n",
        "alpha_hat = torch.cumprod(alphas,axis = 0) \n",
        "# alpha_hat = tensor([0.9950, 0.8955, 0.7612, 0.6089, 0.4567])\n",
        "# take out the values of alpha_hat that corrospond to the timesteps\n",
        "result = alpha_hat.gather(-1,t)\n",
        "# result = tensor([0.8955, 0.6089])\n",
        "# reshape to the dimmension of the input\n",
        "result = result.reshape(-1,1)\n",
        "# result = tensor([[0.8955],[0.6089]])"
      ],
      "metadata": {
        "id": "1UBZuJgaJwnx"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "noise = torch.rand_like(x0)\n",
        "mean = result.sqrt()*x0\n",
        "variance = torch.sqrt(1-result)*noise"
      ],
      "metadata": {
        "id": "BjbPP2nBKX-6"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_t = mean + variance\n",
        "\n",
        "# x_t will have 2 images\n",
        "# x_t[0] and x_t[1]\n",
        "# 1 at timestep 1 with less noise\n",
        "# and 2 at timestep 3 with more noise."
      ],
      "metadata": {
        "id": "O9LKESRXKmiT"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward_diffusion(x0, t, betas = torch.linspace(0.0,1.0,40)):\n",
        "  noise = torch.rand_like(x0)\n",
        "  alphas = 1- betas\n",
        "  alpha_hat = torch.cumprod(alphas, axis = 0)\n",
        "  result = alpha_hat.gather(-1,t).reshape(-1,1)\n",
        "\n",
        "  mean = result.sqrt()*x0\n",
        "  variance = torch.sqrt(1-result)*noise\n",
        "  return mean +variance, noise"
      ],
      "metadata": {
        "id": "OR8hsNJkMsu0"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DiffusionModel:\n",
        "    def __init__(self, start_schedule=0.0001, end_schedule=0.02, timesteps = 300):\n",
        "        self.start_schedule = start_schedule\n",
        "        self.end_schedule = end_schedule\n",
        "        self.timesteps = timesteps\n",
        "        self.betas = torch.linspace(start_schedule, end_schedule, timesteps)\n",
        "        self.alphas = 1 - self.betas\n",
        "        self.alphas_cumprod = torch.cumprod(self.alphas, axis=0)\n",
        "        \n",
        "    def forward(self, x_0, t, device):\n",
        "   \n",
        "        noise = torch.randn_like(x_0)\n",
        "        sqrt_alphas_cumprod_t = self.get_index_from_list(self.alphas_cumprod.sqrt(), t, x_0.shape)\n",
        "        sqrt_one_minus_alphas_cumprod_t = self.get_index_from_list(torch.sqrt(1. - self.alphas_cumprod), t, x_0.shape)\n",
        "            \n",
        "        mean = sqrt_alphas_cumprod_t.to(device) * x_0.to(device)\n",
        "        variance = sqrt_one_minus_alphas_cumprod_t.to(device) * noise.to(device)\n",
        "        \n",
        "        return mean + variance, noise.to(device)\n",
        "      \n",
        "    @torch.no_grad()\n",
        "    def backward(self, x, t, model, **kwargs):\n",
        "        \"\"\"\n",
        "        Calls the model to predict the noise in the image and returns \n",
        "        the denoised image. \n",
        "        Applies noise to this image, if we are not in the last step yet.\n",
        "        \"\"\"\n",
        "  \n",
        "        betas_t = self.get_index_from_list(self.betas, t, x.shape)\n",
        "        sqrt_one_minus_alphas_cumprod_t = self.get_index_from_list(torch.sqrt(1. - self.alphas_cumprod), t, x.shape)\n",
        "        sqrt_recip_alphas_t = self.get_index_from_list(torch.sqrt(1.0 / self.alphas), t, x.shape)\n",
        "        mean = sqrt_recip_alphas_t * (x - betas_t * model(x, t, **kwargs) / sqrt_one_minus_alphas_cumprod_t)\n",
        "        posterior_variance_t = betas_t\n",
        "\n",
        "        if t == 0:\n",
        "            return mean\n",
        "        else:\n",
        "            noise = torch.randn_like(x)\n",
        "            variance = torch.sqrt(posterior_variance_t) * noise \n",
        "            return mean + variance\n",
        "\n",
        "    @staticmethod\n",
        "    def get_index_from_list(values, t, x_shape):\n",
        "        batch_size = t.shape[0]\n",
        "        result = values.gather(-1, t.cpu())\n",
        "\n",
        "        return result.reshape(batch_size, *((1,) * (len(x_shape) - 1))).to(t.device)"
      ],
      "metadata": {
        "id": "xrXPlKzzbmK1"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "diffusion_model = DiffusionModel()"
      ],
      "metadata": {
        "id": "0f33EV9Ab5-D"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inp = torch.randn(200)\n",
        "\n",
        "#t = torch.tensor([0,1,2,3,39])\n",
        "batch_images = torch.stack([inp]*5)"
      ],
      "metadata": {
        "id": "W-jNBt8dRnck"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "diffusion_model.timesteps"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ug90MfRdP1F",
        "outputId": "0f0f6066-e382-45b9-c7bf-4b8299bd2763"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "300"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NO_DISPLAY_IMAGES = 5\n",
        "device = 'cpu'\n",
        "t = torch.linspace(0, diffusion_model.timesteps - 1, NO_DISPLAY_IMAGES).long()\n",
        "noisy_image_batch, _ = diffusion_model.forward(batch_images, t, device)\n"
      ],
      "metadata": {
        "id": "t-0LHbWmb_Z1"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "noisy_image_batch.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rCzNvL5_R7rv",
        "outputId": "a66db8b3-e531-4bd4-d5fe-e4b73a439a31"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 200])"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WR1MvM48eg2j",
        "outputId": "69193549-df6d-43fe-d02a-37299e584119"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([  0,  74, 149, 224, 299])"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, image in enumerate(noisy_image_batch):\n",
        "  print(t[idx].item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90UNnULUeWBM",
        "outputId": "1c9fcaa7-d1ab-4ea4-8c38-fbfe26cd1ca9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "74\n",
            "149\n",
            "224\n",
            "299\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SinusoidalPositionEmbeddings(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.dim = dim\n",
        "\n",
        "    def forward(self, time):\n",
        "        device = time.device\n",
        "        half_dim = self.dim // 2\n",
        "        embeddings = math.log(10000) / (half_dim - 1)\n",
        "        embeddings = torch.exp(torch.arange(half_dim, device=device) * -embeddings)\n",
        "        embeddings = time[:, None] * embeddings[None, :]\n",
        "        embeddings = torch.cat((embeddings.sin(), embeddings.cos()), dim=-1)\n",
        "        return embeddings"
      ],
      "metadata": {
        "id": "6jixo-f1exDC"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embd = SinusoidalPositionEmbeddings(5)\n",
        "embd.forward(t)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xDj1W4OORElQ",
        "outputId": "bcd01fe9-d8f4-4a41-ceb2-8bb273842a1e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0000,  0.0000,  1.0000,  1.0000],\n",
              "        [-0.9851,  0.0074,  0.1717,  1.0000],\n",
              "        [-0.9746,  0.0149, -0.2237,  0.9999],\n",
              "        [-0.8116,  0.0224, -0.5842,  0.9997],\n",
              "        [-0.5216,  0.0299, -0.8532,  0.9996]])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Block(nn.Module):\n",
        "    def __init__(self, channels_in, channels_out, time_embedding_dims, labels, num_filters = 3, downsample=True):\n",
        "        super().__init__()\n",
        "\n",
        "        print('Im him')\n",
        "        \n",
        "        self.time_embedding_dims = time_embedding_dims\n",
        "        self.time_embedding = SinusoidalPositionEmbeddings(time_embedding_dims)\n",
        "        self.labels = labels\n",
        "        \n",
        "        if labels:\n",
        "            self.label_mlp = nn.Linear(1, channels_out)\n",
        "\n",
        "        self.downsample = downsample\n",
        "        \n",
        "        if downsample:\n",
        "            self.lin1 = nn.Linear(channels_in, channels_out)\n",
        "            self.final = nn.Linear(channels_out, channels_out)\n",
        "        else:\n",
        "            self.lin1 = nn.Linear(2*channels_in, channels_out)\n",
        "            self.final = nn.Linear(channels_out, channels_out)\n",
        "        \n",
        "        \n",
        "        self.lin2 = nn.Linear(channels_out, channels_out)\n",
        "\n",
        "\n",
        "        self.bnorm1 = nn.BatchNorm1d(channels_out)\n",
        "        self.bnorm2 = nn.BatchNorm1d(channels_out)\n",
        "        \n",
        "        self.time_mlp = nn.Linear(time_embedding_dims, channels_out)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x, t, **kwargs):\n",
        "\n",
        "        try:\n",
        "          o = self.bnorm1(self.relu(self.lin1(x)))\n",
        "        except:\n",
        "          o = self.relu(self.lin1(x))\n",
        "\n",
        "        o_time = self.relu(self.time_mlp(self.time_embedding(t)))\n",
        "\n",
        "        o = o + o_time\n",
        "        if self.labels:\n",
        "            label = kwargs.get('labels')\n",
        "            o_label = self.relu(self.label_mlp(label))\n",
        "            o = o + o_label\n",
        "   \n",
        "        try:\n",
        "          o = self.bnorm2(self.relu(self.lin2(o)))\n",
        "        except:\n",
        "          o = self.relu(self.lin2(o))\n",
        "\n",
        "        return self.final(o)\n"
      ],
      "metadata": {
        "id": "l0AaKtWUSSY4"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class UNet(nn.Module):\n",
        "    def __init__(self, img_channels = 200, time_embedding_dims = 128, labels = False, sequence_channels = (64, 128, 256, 512)):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.time_embedding_dims = time_embedding_dims\n",
        "        sequence_channels_rev = reversed(sequence_channels)\n",
        "        \n",
        "        self.downsampling = nn.ModuleList([Block(channels_in, channels_out, time_embedding_dims, labels) for channels_in, channels_out in zip(sequence_channels, sequence_channels[1:])])\n",
        "        self.upsampling = nn.ModuleList([Block(channels_in, channels_out, time_embedding_dims, labels,downsample=False) for channels_in, channels_out in zip(sequence_channels[::-1], sequence_channels[::-1][1:])])\n",
        "        \n",
        "        #self.conv1 = nn.Conv2d(img_channels, sequence_channels[0], 3, padding=1)\n",
        "        self.lin1 = nn.Linear(img_channels, sequence_channels[0])\n",
        "        #self.conv2 = nn.Conv2d(sequence_channels[0], img_channels, 1)\n",
        "        self.lin2 = nn.Linear(sequence_channels[0], img_channels)\n",
        "\n",
        "    \n",
        "    def forward(self, x, t, **kwargs):\n",
        "        residuals = []\n",
        "        o = self.lin1(x)\n",
        "        \n",
        "        for ds in self.downsampling:\n",
        "            o = ds(o, t, **kwargs)\n",
        "            residuals.append(o)\n",
        "        \n",
        "        for us, res in zip(self.upsampling, reversed(residuals)):\n",
        "            o = us(torch.cat((o, res), dim=1), t, **kwargs)   \n",
        "        \n",
        "        return self.lin2(o)"
      ],
      "metadata": {
        "id": "C65whP8hSgca"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NO_EPOCHS = 1000\n",
        "PRINT_FREQUENCY = 500\n",
        "LR = 0.0001\n",
        "BATCH_SIZE = 2\n",
        "VERBOSE = True\n",
        "\n",
        "unet = UNet(labels=False)\n",
        "unet.to(device)\n",
        "optimizer = torch.optim.Adam(unet.parameters(), lr=LR)"
      ],
      "metadata": {
        "id": "gmCKGYuySUjf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55e0519b-1776-4124-cc96-76a09e72ae63"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Im him\n",
            "Im him\n",
            "Im him\n",
            "Im him\n",
            "Im him\n",
            "Im him\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_noise_distribution(noise, predicted_noise):\n",
        "    plt.hist(noise.cpu().numpy().flatten(), density = True, alpha = 0.8, label = \"ground truth noise\")\n",
        "    plt.hist(predicted_noise.cpu().numpy().flatten(), density = True, alpha = 0.8, label = \"predicted noise\")\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "sEao6ZishcSB"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(1000):\n",
        "    mean_epoch_loss = []\n",
        "    \n",
        "    batch = torch.stack([inp] * BATCH_SIZE)\n",
        "    t = torch.randint(0, diffusion_model.timesteps, (BATCH_SIZE,)).long().to(device)\n",
        "\n",
        "    batch_noisy, noise = diffusion_model.forward(batch, t, device) \n",
        "\n",
        "    predicted_noise = unet(batch_noisy, t)\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    #print('noise',noise)\n",
        "    #print('predicted_noise',predicted_noise)\n",
        "    loss = torch.nn.functional.mse_loss(noise, predicted_noise) \n",
        "    mean_epoch_loss.append(loss.item())\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    if epoch % PRINT_FREQUENCY == 0:\n",
        "        print('---')\n",
        "        print(f\"Epoch: {epoch} | Train Loss {np.mean(mean_epoch_loss)}\")\n",
        "        if VERBOSE:\n",
        "            with torch.no_grad():\n",
        "                #plot_noise_prediction(noise[0], predicted_noise[0])\n",
        "                plot_noise_distribution(noise, predicted_noise)"
      ],
      "metadata": {
        "id": "Gq_z_LCJIfOa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    img = torch.randn(200).to(device)\n",
        "    for i in reversed(range(diffusion_model.timesteps)):\n",
        "        t = torch.full((1,), i, dtype=torch.long, device=device)\n",
        "        img = diffusion_model.backward(img, t, unet.eval())\n",
        "        if i % 50 == 0:\n",
        "            print('i',i)\n",
        "            print(img)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Og2kqa4oqPNR",
        "outputId": "e44c39c4-4550-474a-f2b0-1ed622e75169"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i 250\n",
            "tensor([[-0.2163, -1.5698,  0.4640,  0.8863, -1.6537, -0.5921,  0.6640,  2.6482,\n",
            "         -1.9482,  1.5833, -0.8782, -1.6244,  2.2171, -1.3198, -2.5248, -0.8760,\n",
            "          2.9928, -0.1769,  2.7066,  0.7799,  0.1725, -1.3603,  1.5925, -1.4317,\n",
            "          1.1925, -0.9554,  3.5365,  0.8025,  2.6361, -0.8484, -1.8532, -1.1197,\n",
            "         -4.5452, -3.2742,  2.9618,  2.0152,  0.1547, -0.8961,  2.7545,  1.7410,\n",
            "         -3.6228, -1.5940, -0.0572,  0.4530,  0.6106,  3.8288, -1.9655,  3.8979,\n",
            "          1.9226,  0.7454, -0.3775, -0.1642,  2.4786, -5.1964,  0.7753, -2.3378,\n",
            "         -0.9064,  1.4763,  0.3311, -0.4336, -4.4547, -4.6805, -1.7745, -0.4417,\n",
            "         -5.5068,  0.8827,  1.2705,  2.5806,  2.1320, -0.7591,  2.0094,  0.0381,\n",
            "         -0.0870, -0.2275,  2.1366, -1.6840,  1.2045,  3.4297,  3.2054,  0.0113,\n",
            "          1.5207,  3.1864,  0.7817, -0.1892,  1.2029,  0.4253,  1.1504, -1.9219,\n",
            "         -2.7743,  0.1816, -0.2414,  1.9460, -2.2942, -0.2346,  0.3847, -1.6894,\n",
            "         -1.6810,  1.7199, -3.6393, -1.0633, -0.8397, -3.5602,  1.6435, -2.9349,\n",
            "         -1.2157, -2.3690,  0.1119,  0.3743, -0.2966,  1.0924,  0.6693,  4.5317,\n",
            "          2.6073,  3.3719, -0.7663,  0.1455, -1.9547, -0.1986, -3.3026, -4.5891,\n",
            "         -0.4202,  1.0369, -1.3981, -0.7553,  1.2377,  2.5388, -3.1377,  1.3282,\n",
            "         -2.1102, -2.2656,  1.4786, -2.5883, -0.1249,  2.6984,  3.3630, -2.4779,\n",
            "         -1.3414,  0.0264, -2.8727,  0.9869, -0.0278, -3.1416,  2.6653,  2.8882,\n",
            "         -0.3337,  1.0155, -2.5037, -3.1471, -1.5396,  2.8370, -0.4775, -4.7469,\n",
            "          1.5957, -1.9575,  0.7767, -0.6208, -0.8013, -0.3083, -4.0638, -1.2874,\n",
            "         -2.0918,  2.5728, -2.0686,  0.8162,  2.0549,  0.1189, -0.6281, -4.0619,\n",
            "         -1.6053,  0.0496, -0.7562, -2.3177,  2.2222,  1.6500, -2.6124,  3.2216,\n",
            "         -1.8830, -0.6924,  2.8251, -3.3227, -0.1564,  4.1334,  3.1320,  1.8814,\n",
            "         -1.5538,  2.7320,  0.9653,  0.8139,  0.6640, -5.6517,  0.1891, -2.5173,\n",
            "         -0.5067, -2.0893, -1.2809,  3.0662,  1.7435, -1.8374,  1.3893, -0.0506]])\n",
            "i 200\n",
            "tensor([[-2.1425e+00, -5.1535e-01,  2.9980e-01,  2.5814e+00, -3.2199e+00,\n",
            "         -1.6784e+00, -4.6302e-01,  4.8175e+00, -3.4613e+00,  2.1244e+00,\n",
            "         -1.7935e+00, -3.7144e+00,  2.9070e+00,  1.8923e-01, -3.7935e+00,\n",
            "         -1.4433e+00,  5.8649e+00,  5.9243e-01,  4.1609e+00,  3.0780e-01,\n",
            "         -6.5019e-01, -2.6850e+00,  7.5296e-01, -1.3660e+00,  1.5590e+00,\n",
            "         -3.4906e+00,  6.0242e+00,  6.6667e-01,  3.7543e+00, -3.1900e+00,\n",
            "         -4.1160e+00, -1.5434e+00, -8.3389e+00, -5.7891e+00,  3.2794e+00,\n",
            "          5.0276e+00,  1.2077e+00, -8.6055e-01,  3.3600e+00,  3.7626e+00,\n",
            "         -5.3482e+00, -2.7595e+00, -2.9957e-02,  7.1394e-01,  4.9970e-01,\n",
            "          5.0000e+00, -4.2376e+00,  7.2524e+00,  1.1927e+00,  4.0785e-01,\n",
            "         -8.0051e-01, -1.0723e+00,  3.9922e+00, -7.3481e+00,  5.2994e-01,\n",
            "         -2.3072e+00, -2.4444e+00,  1.6138e+00,  2.4404e-01,  1.7545e+00,\n",
            "         -6.5944e+00, -6.2053e+00, -2.0768e+00, -6.1509e-01, -6.0364e+00,\n",
            "          1.2690e+00,  1.8899e+00,  2.0793e+00,  2.1357e+00,  5.7590e-01,\n",
            "          1.7992e+00,  3.0856e-04,  2.7096e+00, -2.0001e+00,  3.2909e+00,\n",
            "         -3.6394e+00,  2.6780e+00,  3.9194e+00,  5.7535e+00, -4.5627e-01,\n",
            "          6.7117e+00,  4.5705e+00,  9.3418e-01, -7.7878e-01,  2.9743e+00,\n",
            "          1.0852e-01,  2.9837e+00, -2.5587e+00, -3.9194e+00, -1.4988e+00,\n",
            "          1.2745e+00,  1.3283e+00, -4.0910e+00, -3.6364e-01, -8.1248e-01,\n",
            "         -5.6246e-01, -2.0747e+00,  2.0859e+00, -5.4111e+00, -1.4908e+00,\n",
            "         -2.4984e+00, -6.7689e+00,  2.3600e+00, -4.3262e+00, -2.2452e+00,\n",
            "         -4.6230e+00, -8.2913e-01,  6.6163e-01, -5.7356e-01,  1.9429e+00,\n",
            "          2.4147e+00,  6.1824e+00,  3.0893e+00,  5.3296e+00, -2.4987e-01,\n",
            "          1.1546e+00, -3.7999e+00,  1.1799e+00, -3.3413e+00, -6.3027e+00,\n",
            "         -1.1219e+00,  1.9375e+00, -9.3098e-01, -1.9697e+00,  1.0364e+00,\n",
            "          4.6704e+00, -2.5180e+00,  1.8258e-01, -3.0328e+00, -4.5563e+00,\n",
            "          1.2348e+00, -3.3669e+00, -7.9745e-01,  5.3341e+00,  5.1465e+00,\n",
            "         -2.6925e+00, -1.8505e+00, -1.2757e+00, -3.6155e+00,  1.1422e+00,\n",
            "         -1.1959e+00, -5.2334e+00,  4.1894e+00,  5.5587e+00,  1.1165e+00,\n",
            "          1.8627e+00, -3.1054e+00, -3.8573e+00, -4.1600e-01,  4.0540e+00,\n",
            "          9.8038e-01, -5.7264e+00,  2.3771e+00, -2.6770e+00,  3.6148e+00,\n",
            "         -2.0653e+00, -1.3220e+00, -8.2817e-01, -5.8342e+00, -9.6663e-01,\n",
            "         -3.8577e+00,  4.1052e+00, -2.2221e+00,  6.9671e-01,  2.8447e+00,\n",
            "          5.4367e-01, -1.9557e+00, -4.6799e+00, -4.2197e+00,  1.2801e+00,\n",
            "          7.3301e-01, -3.2314e+00,  3.6230e+00,  3.9851e+00, -3.7237e+00,\n",
            "          2.9528e+00, -2.6881e+00, -1.2398e+00,  2.8810e+00, -5.8135e+00,\n",
            "          8.9573e-01,  6.8454e+00,  5.0570e+00,  2.9538e+00, -2.7638e+00,\n",
            "          4.8147e+00,  1.2923e+00,  3.2918e-01,  1.8422e+00, -7.8537e+00,\n",
            "          1.3596e+00, -6.2523e+00, -3.7467e-01, -2.9056e+00, -2.2143e+00,\n",
            "          4.5829e+00,  3.6157e+00, -5.0113e+00,  1.6002e+00, -1.3776e+00]])\n",
            "i 150\n",
            "tensor([[ -1.4971,  -1.5438,   0.3075,   2.5459,  -4.5826,  -1.0471,  -1.1245,\n",
            "           5.7816,  -3.3775,   3.0455,  -2.5019,  -4.6041,   6.0814,   0.8837,\n",
            "          -5.5062,  -1.7639,   7.3014,  -1.3465,   6.0383,   0.0619,  -1.0708,\n",
            "          -4.7444,   2.1109,  -3.3549,   4.1245,  -5.1796,   7.3887,   0.4911,\n",
            "           5.5259,  -4.5880,  -5.4398,  -1.5424, -11.6653,  -6.0977,   3.7270,\n",
            "           6.5968,   1.6652,   0.1224,   4.6089,   4.7274,  -8.2174,  -2.7195,\n",
            "           1.0713,   0.2129,   2.4092,   8.5843,  -4.1138,   9.7667,   0.8316,\n",
            "           1.2925,  -0.6778,  -1.0946,   5.3610,  -9.6567,   0.2487,  -3.8722,\n",
            "          -2.2452,   1.3679,   1.9618,   2.9534,  -8.4180,  -6.9044,  -1.7843,\n",
            "          -2.4312,  -7.2071,   1.3205,   2.3501,   2.8619,   2.6844,   1.7858,\n",
            "           4.7343,  -0.4106,   2.9158,  -1.9436,   4.6603,  -5.8152,   4.4485,\n",
            "           3.7352,   7.6301,   0.3548,   8.1398,   6.8583,   0.9594,  -1.6857,\n",
            "           4.2593,   0.9058,   4.1508,  -3.5893,  -5.1669,  -3.0150,   3.0268,\n",
            "           2.6673,  -5.4581,  -0.1687,  -1.1065,  -2.3753,  -2.2945,   2.2815,\n",
            "          -6.3276,  -2.6373,  -2.8718,  -8.9921,   3.8343,  -5.4479,  -3.8437,\n",
            "          -6.9131,  -1.2379,   0.6334,  -1.0248,   2.7462,   4.0284,   9.7044,\n",
            "           4.3263,   4.8218,  -0.9787,   1.1131,  -4.9249,   2.0973,  -5.8698,\n",
            "         -10.1279,  -0.1584,   1.8676,  -2.5327,  -3.2361,   0.6045,   8.0051,\n",
            "          -3.8635,   0.1865,  -4.0377,  -5.3740,   1.6074,  -4.3195,  -0.8852,\n",
            "           8.9817,   7.8418,  -4.9712,  -1.9782,  -2.8108,  -4.3788,   1.9853,\n",
            "          -2.4492,  -7.3868,   6.8035,   7.4158,   0.6300,   3.7702,  -5.2505,\n",
            "          -4.4593,  -1.2320,   5.7001,   1.7298,  -8.3230,   3.3138,  -3.9871,\n",
            "           4.7114,  -3.9213,  -0.6392,  -1.9962,  -6.1773,  -1.6021,  -3.7904,\n",
            "           4.9471,  -3.2569,  -0.3977,   4.3592,   0.9284,  -3.1926,  -6.4644,\n",
            "          -4.9934,   1.5307,   2.5215,  -4.7748,   3.8483,   6.7550,  -6.5517,\n",
            "           4.1647,  -4.1042,  -0.3895,   4.0271,  -7.1419,   1.5230,  11.8092,\n",
            "           7.7192,   3.6758,  -4.8648,   7.0927,   0.9083,  -0.7921,   2.9438,\n",
            "         -11.8037,   2.1139,  -7.7262,  -0.5900,  -4.7280,  -2.4524,   5.3413,\n",
            "           3.2843,  -7.4294,   0.9147,  -2.7912]])\n",
            "i 100\n",
            "tensor([[ -2.5751,  -2.0681,   0.2015,   3.6897,  -4.9719,  -0.3187,  -1.3564,\n",
            "           6.7638,  -3.5577,   4.3006,  -3.2244,  -5.8097,   6.5856,   2.7069,\n",
            "          -6.0182,  -2.1986,   8.9011,  -3.2873,   8.1141,   1.1452,  -2.0445,\n",
            "          -5.5705,   3.4781,  -4.6734,   6.3606,  -7.2142,   8.6827,   1.3231,\n",
            "           6.9526,  -5.3914,  -7.0770,  -1.3881, -15.1814,  -7.6830,   4.9375,\n",
            "           7.7480,   2.5584,   0.7938,   6.4744,   5.6446,  -9.1462,  -3.2551,\n",
            "           1.9288,  -0.3443,   2.8934,   9.8845,  -5.6230,  11.6547,   0.9557,\n",
            "           0.6305,  -0.5514,  -1.3902,   6.0477, -12.2689,   1.2274,  -5.1518,\n",
            "          -1.6695,   2.5156,   2.5699,   2.4048, -10.9046,  -9.8084,  -2.1347,\n",
            "          -3.6937,  -8.2382,   1.9031,   2.0987,   3.2782,   3.5536,   1.2189,\n",
            "           5.7430,   0.7953,   3.8050,  -2.3724,   5.7594,  -5.7282,   5.6861,\n",
            "           4.1623,   8.6699,   0.4232,  10.9805,  10.0139,   2.0554,  -2.0678,\n",
            "           4.6749,   0.4446,   5.3664,  -5.1454,  -6.1367,  -3.9435,   3.2596,\n",
            "           3.5247,  -6.2177,   0.5024,  -2.2200,  -3.6989,  -2.0397,   2.1888,\n",
            "          -8.5689,  -3.5363,  -3.3124,  -9.5985,   5.9735,  -6.9317,  -4.1321,\n",
            "          -8.9895,  -1.7477,   0.5513,  -0.7172,   4.0966,   4.2495,  11.4473,\n",
            "           4.0507,   6.3687,  -0.2442,   1.3067,  -6.0088,   2.7281,  -7.2396,\n",
            "         -11.9067,   1.5660,   1.4390,  -3.8908,  -4.3624,   1.9062,  10.2339,\n",
            "          -6.1052,  -0.0883,  -4.5355,  -7.9199,   2.1094,  -5.6684,  -1.1722,\n",
            "          11.0796,  11.0619,  -4.8901,  -2.9212,  -4.3439,  -4.8645,   2.6736,\n",
            "          -3.7800,  -9.2508,   8.6795,   8.2255,   1.0722,   4.2125,  -5.7887,\n",
            "          -5.5060,  -0.0977,   7.5183,   1.2515, -10.8815,   4.5859,  -5.8929,\n",
            "           7.2167,  -4.9948,  -1.5106,  -2.3247,  -7.7981,  -2.2976,  -4.4737,\n",
            "           5.9241,  -4.0165,  -0.5051,   5.1961,   0.6498,  -4.4246,  -8.3221,\n",
            "          -5.0337,   1.9055,   3.5086,  -5.3521,   3.7926,   7.9965,  -9.0289,\n",
            "           5.3193,  -5.6811,   1.5596,   5.1680, -10.7253,   0.7532,  15.2570,\n",
            "           8.2380,   3.6154,  -5.6610,   9.8925,   1.4380,  -0.4338,   4.2704,\n",
            "         -14.1685,   3.2753,  -9.7359,  -1.2492,  -5.7646,  -1.8000,   7.5277,\n",
            "           4.2589, -10.3058,   1.0164,  -2.9024]])\n",
            "i 50\n",
            "tensor([[ -1.7227,  -1.8266,   0.1759,   4.6261,  -5.8049,  -0.8159,  -1.6576,\n",
            "           7.7321,  -2.9864,   4.6184,  -4.5281,  -5.9426,   8.1661,   3.0021,\n",
            "          -7.7029,  -2.2676,   8.8456,  -3.5400,   8.6317,   1.2539,  -2.7607,\n",
            "          -6.7676,   4.0558,  -5.3146,   6.6181,  -8.5325,   9.5642,   1.1781,\n",
            "           7.2775,  -5.8843,  -7.3565,  -2.1489, -16.5849,  -8.3749,   5.5047,\n",
            "           9.2836,   2.7905,   0.9528,   6.6403,   6.9925, -10.9033,  -4.1779,\n",
            "           2.3754,  -0.4977,   3.7400,  11.3700,  -6.7102,  12.8208,   1.1641,\n",
            "           0.6401,  -0.7936,  -1.2708,   7.1089, -14.4756,   1.8109,  -5.4640,\n",
            "          -1.7314,   3.1397,   2.3551,   3.0890, -12.9624, -11.2135,  -2.3654,\n",
            "          -4.0432,  -8.7790,   1.5319,   2.7902,   3.6998,   3.9610,  -0.1892,\n",
            "           6.8260,   1.1678,   5.1855,  -1.2841,   7.0777,  -7.1356,   5.2180,\n",
            "           4.4527,  10.7899,   0.6139,  12.4744,  11.8377,   3.2905,  -2.6249,\n",
            "           4.6543,   0.8564,   6.4343,  -5.0714,  -5.8996,  -3.8315,   3.2324,\n",
            "           4.4823,  -6.7855,  -0.5951,  -2.4722,  -4.1039,  -3.6038,   2.1644,\n",
            "         -10.3891,  -4.0759,  -3.2211, -11.0235,   5.5939,  -7.5719,  -4.2908,\n",
            "         -10.4835,  -1.3253,   0.5175,  -0.5284,   5.1037,   5.4000,  12.7256,\n",
            "           4.5730,   6.8675,  -0.6509,   1.9513,  -6.8218,   3.5184,  -7.7713,\n",
            "         -12.9508,   2.7450,   1.3450,  -3.6498,  -4.0472,   1.9042,  11.4038,\n",
            "          -7.9198,   0.1777,  -6.1205,  -8.2477,   1.6641,  -5.8281,  -1.2846,\n",
            "          11.6383,  12.2894,  -5.4286,  -3.6042,  -5.3041,  -5.4077,   2.5410,\n",
            "          -3.8342, -10.4347,   9.2663,   9.6670,   1.4688,   5.4218,  -6.2186,\n",
            "          -5.2005,   0.5824,   8.6248,   1.3753, -12.5900,   5.6700,  -6.0660,\n",
            "           7.7757,  -6.4508,  -2.9065,  -2.6607,  -8.6091,  -3.2152,  -6.1708,\n",
            "           6.6918,  -4.4772,  -0.8784,   6.7224,  -0.4325,  -5.1453,  -9.8180,\n",
            "          -6.1808,   2.1391,   3.8594,  -5.3466,   4.5767,   8.9697, -10.4408,\n",
            "           7.1271,  -6.3986,   1.8979,   5.5709, -13.2737,   0.2160,  17.8719,\n",
            "           9.2619,   2.9800,  -6.1618,  10.7420,   1.8047,  -0.1554,   4.5669,\n",
            "         -17.4032,   4.5956, -11.0393,  -2.6009,  -7.4918,  -1.7055,   9.6525,\n",
            "           4.4241, -12.0957,   1.4310,  -4.1235]])\n",
            "i 0\n",
            "tensor([[ -1.7866,  -2.0015,   0.0356,   5.1981,  -6.6527,  -0.3567,  -1.6124,\n",
            "           8.2086,  -3.3961,   4.4420,  -4.4842,  -5.9206,   8.0006,   3.5380,\n",
            "          -7.7923,  -2.0166,   9.6007,  -3.6699,   9.2184,   1.1164,  -3.2642,\n",
            "          -6.7838,   4.1443,  -5.6221,   6.3915,  -8.5154,  10.1600,   0.2647,\n",
            "           7.6250,  -6.3817,  -7.3279,  -2.2603, -17.4379,  -8.9335,   5.4573,\n",
            "           9.3331,   2.7864,   1.3350,   6.7123,   7.5737, -11.6068,  -4.8768,\n",
            "           2.9086,  -0.6505,   3.7739,  12.3415,  -6.5285,  12.6748,   1.2388,\n",
            "           0.3741,  -0.4973,  -1.8651,   7.5801, -15.0890,   2.2409,  -5.5304,\n",
            "          -1.6694,   3.2654,   2.2935,   3.4077, -13.2451, -11.0256,  -2.6543,\n",
            "          -4.3371,  -8.9268,   1.0568,   2.7670,   4.6316,   3.8317,  -0.1694,\n",
            "           7.3753,   1.2467,   5.4668,  -1.1102,   7.5659,  -7.4642,   4.8183,\n",
            "           4.2951,  11.1854,  -0.0822,  12.5455,  12.0539,   3.1200,  -2.7856,\n",
            "           4.5455,   1.3130,   6.5826,  -5.1499,  -5.8922,  -4.3298,   3.0540,\n",
            "           4.5986,  -6.9271,  -0.6221,  -2.6261,  -3.8970,  -3.6385,   2.6994,\n",
            "         -10.7235,  -4.2929,  -3.3762, -11.1639,   5.6565,  -8.1421,  -4.7862,\n",
            "         -11.2321,  -0.7139,   0.4976,  -0.4146,   5.8123,   4.9660,  13.3553,\n",
            "           4.6531,   6.9529,   0.1297,   2.0361,  -7.2470,   3.8170,  -7.8505,\n",
            "         -13.5313,   3.0859,   1.3942,  -3.8603,  -3.9791,   1.9822,  12.1793,\n",
            "          -8.5229,   0.8318,  -5.8143,  -8.5621,   1.6788,  -6.0125,  -1.6998,\n",
            "          11.8762,  13.1624,  -6.0057,  -3.9994,  -5.8535,  -6.4222,   2.6717,\n",
            "          -4.0482, -10.8607,   9.7315,   9.8009,   0.8867,   5.4092,  -6.2978,\n",
            "          -5.2405,   0.3150,   9.5946,   1.3600, -12.9188,   5.9949,  -6.6533,\n",
            "           8.1113,  -6.4464,  -2.8542,  -2.8874,  -8.7453,  -3.3367,  -6.7082,\n",
            "           7.3809,  -4.6286,  -1.2817,   7.1566,  -0.0841,  -5.4942, -10.1408,\n",
            "          -6.3871,   1.8976,   4.1962,  -5.3778,   5.2485,   8.4073, -10.4630,\n",
            "           7.5678,  -6.9349,   1.7996,   5.9641, -13.8136,   0.2457,  19.0034,\n",
            "           9.7420,   2.9093,  -7.0588,  11.3017,   2.1429,  -0.4847,   4.5499,\n",
            "         -17.9961,   4.8582, -11.8151,  -2.6741,  -7.3561,  -2.2618,  10.4282,\n",
            "           4.6814, -12.9017,   1.5891,  -4.4860]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RlcfACfKQElM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}