{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVrLQ7IrSAwr",
        "outputId": "46979445-37e1-4db2-a9c2-405704237b50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting unet\n",
            "  Downloading unet-0.7.7-py2.py3-none-any.whl (8.1 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from unet) (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->unet) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->unet) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->unet) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->unet) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->unet) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->unet) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->unet) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->unet) (16.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->unet) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->unet) (1.3.0)\n",
            "Installing collected packages: unet\n",
            "Successfully installed unet-0.7.7\n"
          ]
        }
      ],
      "source": [
        "pip install unet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "dvmL2CuRTKcQ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from unet import UNet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "1lym-5wgXlBY"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install einops\n",
        "from einops import rearrange, reduce\n",
        "from einops.layers.torch import Rearrange"
      ],
      "metadata": {
        "id": "pE_93u2fXzwJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "from functools import partial\n",
        "from torch import nn, einsum"
      ],
      "metadata": {
        "id": "mLpDCuq9YSEK"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "qnlV7PSvUYD2"
      },
      "outputs": [],
      "source": [
        "CONFIG = {}\n",
        "CONFIG['data_x_path'] = '/content/perov_5_raw_train_dist_mat.pt'\n",
        "CONFIG['data_ead_path'] = '/content/perov_5_raw_train_ead_mat.pt'\n",
        "CONFIG['composition_path'] = '/content/perov_5_raw_train_composition_mat.pt'\n",
        "CONFIG['cell_path'] = '/content/perov_5_raw_train_cell_mat.pt'\n",
        "CONFIG['data_y_path'] = \"/content/targets.csv\"\n",
        "CONFIG['unprocessed_path'] = '/content/perov_5_raw_train_unprocessed.txt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "kLdi2ZjiU8ic",
        "outputId": "afb5fb61-bb6b-4082-9514-b39e406b2b5d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/perov_5_raw_train_dist_mat.pt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "CONFIG['data_x_path']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "chSjccc2VGnJ"
      },
      "outputs": [],
      "source": [
        "unprocessed = set()\n",
        "with open(CONFIG['unprocessed_path'], 'r') as f:\n",
        "    for l in f.readlines():\n",
        "        unprocessed.add(int(l))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "6QuE2YaAT85Z"
      },
      "outputs": [],
      "source": [
        "dist_mat = torch.load(CONFIG['data_x_path'] ,map_location=torch.device('cpu')).to(\"cpu\")\n",
        "ead_mat = torch.load(CONFIG['data_ead_path'],map_location=torch.device('cpu')).to(\"cpu\")\n",
        "composition_mat = torch.load(CONFIG['composition_path'],map_location=torch.device('cpu')).to(\"cpu\")\n",
        "cell_mat = torch.load(CONFIG['cell_path'],map_location=torch.device('cpu')).to(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "4nKIzNtzYqDb"
      },
      "outputs": [],
      "source": [
        "# build index\n",
        "_ind = [i for i in range(dist_mat.shape[0]) if i not in unprocessed]\n",
        "indices = torch.tensor(_ind, dtype=torch.long).to(\"cpu\")\n",
        "\n",
        "# select rows torch.Size([27136, 1])\n",
        "dist_mat = dist_mat[indices] # the torch.load needs the index in tensor format to convert the loaded file in a tensor.\n",
        "ead_mat = ead_mat[indices]\n",
        "composition_mat = composition_mat[indices]\n",
        "cell_mat = cell_mat[indices]\n",
        "\n",
        "# normalize composition\n",
        "sums = torch.sum(composition_mat, axis=1).view(-1,1)\n",
        "composition_mat = composition_mat / sums\n",
        "composition_mat = torch.cat((composition_mat, sums), dim=1)\n",
        "\n",
        "y = []\n",
        "with open(CONFIG['data_y_path'], 'r') as f:\n",
        "    for i, d in enumerate(f.readlines()):\n",
        "        if i not in unprocessed:\n",
        "            y.append(float(d.split(',')[1]))\n",
        "\n",
        "data_y = np.reshape(np.array(y), (-1,1))\n",
        "\n",
        "data_y = torch.from_numpy(data_y)\n",
        "data_y = data_y.to(torch.float32)\n",
        "\n",
        "data_x = torch.cat((ead_mat/1000000, dist_mat, cell_mat, composition_mat, data_y), dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rrPMsGdWaVHY",
        "outputId": "3e5bb787-3041-47af-a14f-a458a1ef6aec"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([11356, 709])"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "data_x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "L4iOtk4baZKh"
      },
      "outputs": [],
      "source": [
        "mask = data_x[:, 600] <= 10\n",
        "data_x = data_x[mask]\n",
        "#data_x, data_y = data_x[:, 0:708] , data_x[:,708]\n",
        "data_x, composition_mat, data_y = data_x[:, 0:607], data_x[:,607:708] , data_x[:,708]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "f0wlv8cwnyh1"
      },
      "outputs": [],
      "source": [
        "scaler = MinMaxScaler()\n",
        "scaler.fit(data_x)\n",
        "data_x = scaler.transform(data_x)\n",
        "#joblib.dump(scaler, self.CONFIG.scaler_path) # save the scaler to be used for later purpose on testing data.\n",
        "\n",
        "comp1, comp2 = composition_mat[:, 0:96], composition_mat[:,100]/5\n",
        "comp1 = (comp1.to(torch.float32))\n",
        "comp2 = comp2.to(torch.float32).view(-1,1)\n",
        "\n",
        "composition_mat_add = torch.cat((comp1,comp2), dim=1)\n",
        "\n",
        "data_x = torch.from_numpy(data_x)\n",
        "data_x = data_x.to(torch.float32)\n",
        "\n",
        "#composition_mat = torch.from_numpy(composition_mat_add)\n",
        "#composition_mat = composition_mat.to(torch.float32)\n",
        "\n",
        "data_x = torch.cat((10*data_x,composition_mat_add), dim=1)\n",
        "\n",
        "data_y = data_y.view(-1,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "kVuISnZ1bKe0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "sELE2lpgdvQM"
      },
      "outputs": [],
      "source": [
        "#data_x = data_x[0:100,0:15]\n",
        "#data_y = data_y[0:100,0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fHl9lWEXpDee",
        "outputId": "ce0e8f28-4e6b-43e1-d6b5-28a01d2fc377"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([11356, 704])"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ],
      "source": [
        "data_x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "qCvheOoTbSai"
      },
      "outputs": [],
      "source": [
        "CONFIG['seed'] = 42\n",
        "CONFIG['split_ratio'] = 0.2\n",
        "batch_size = 200"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rm6YGKP8ZXJP",
        "outputId": "07a21663-2de7-40e7-99ec-4d51ba78c411"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([True, True, True,  ..., True, True, True])\n"
          ]
        }
      ],
      "source": [
        "# train/test split and create torch dataloader\n",
        "xtrain, xtest, ytrain, ytest = train_test_split(data_x, data_y, test_size=CONFIG['split_ratio'], random_state= CONFIG['seed'])\n",
        "\n",
        "if not isinstance(xtrain, torch.Tensor):\n",
        "    x_train = torch.tensor(xtrain, dtype=torch.float)\n",
        "else:\n",
        "    x_train = xtrain\n",
        "\n",
        "if not isinstance(ytrain, torch.Tensor):\n",
        "    y_train = torch.tensor(ytrain, dtype=torch.float)\n",
        "else:\n",
        "    y_train = ytrain\n",
        "\n",
        "if not isinstance(xtest, torch.Tensor):\n",
        "    x_test = torch.tensor(xtest, dtype=torch.float)\n",
        "else:\n",
        "    x_test = xtest\n",
        "\n",
        "if not isinstance(ytest, torch.Tensor):\n",
        "    y_test = torch.tensor(ytest, dtype=torch.float)\n",
        "else:\n",
        "    y_test = ytest\n",
        "\n",
        "\n",
        "indices = ~torch.any(x_train.isnan(),dim=1)\n",
        "\n",
        "x_train = x_train[indices]\n",
        "y_train = y_train[indices] # y_train is the condition\n",
        "\n",
        "indices = ~torch.any(x_train[:,:601] > 10 ,dim=1)\n",
        "x_train = x_train[indices]\n",
        "y_train = y_train[indices]\n",
        "\n",
        "indices = ~torch.any(x_test.isnan(),dim=1)\n",
        "print(indices) # tensor([True, True, True,  ..., True, True, True])\n",
        "\n",
        "x_test = x_test[indices]\n",
        "y_test = y_test[indices]\n",
        "indices = ~torch.any(x_test[:,:601] > 10 ,dim=1)\n",
        "x_test = x_test[indices]\n",
        "y_test = y_test[indices]\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    TensorDataset(x_train, y_train),\n",
        "    batch_size=batch_size, shuffle=True, drop_last=False\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    TensorDataset(x_test, y_test),\n",
        "    batch_size=batch_size, shuffle=False, drop_last=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZzMfEJCrcJig",
        "outputId": "c82df38d-ebec-400b-8942-a5068c3372a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "200\n",
            "torch.Size([200, 704])\n",
            "200\n",
            "torch.Size([200, 704])\n",
            "200\n",
            "torch.Size([200, 704])\n",
            "200\n",
            "torch.Size([200, 704])\n",
            "200\n",
            "torch.Size([200, 704])\n",
            "200\n",
            "torch.Size([200, 704])\n",
            "200\n",
            "torch.Size([200, 704])\n",
            "200\n",
            "torch.Size([200, 704])\n",
            "200\n",
            "torch.Size([200, 704])\n",
            "200\n",
            "torch.Size([200, 704])\n",
            "200\n",
            "torch.Size([200, 704])\n",
            "72\n",
            "torch.Size([72, 704])\n"
          ]
        }
      ],
      "source": [
        "for test in test_loader:\n",
        "  print(len(test[0]))\n",
        "  print(test[0].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "c1xro6IbTNX-"
      },
      "outputs": [],
      "source": [
        "class DiffusionModel:\n",
        "    def __init__(self, start_schedule=0.0001, end_schedule=0.02, timesteps = 500):\n",
        "        self.start_schedule = start_schedule\n",
        "        self.end_schedule = end_schedule\n",
        "        self.timesteps = timesteps\n",
        "        self.betas = torch.linspace(start_schedule, end_schedule, timesteps)\n",
        "        self.alphas = 1 - self.betas\n",
        "        self.alphas_cumprod = torch.cumprod(self.alphas, axis=0)\n",
        "\n",
        "    def forward(self, x_0, t, device):\n",
        "        #noise = torch.randn(200)\n",
        "        noise = torch.randn_like(x_0)\n",
        "        sqrt_alphas_cumprod_t = self.get_index_from_list(self.alphas_cumprod.sqrt(), t, x_0.shape)\n",
        "        sqrt_one_minus_alphas_cumprod_t = self.get_index_from_list(torch.sqrt(1. - self.alphas_cumprod), t, x_0.shape)\n",
        "\n",
        "        mean = sqrt_alphas_cumprod_t.to(device) * x_0.to(device)\n",
        "        variance = sqrt_one_minus_alphas_cumprod_t.to(device) * noise.to(device)\n",
        "\n",
        "        return mean + variance, noise.to(device)\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def backward(self, x, t, model, **kwargs):\n",
        "        \"\"\"\n",
        "        Calls the model to predict the noise in the image and returns\n",
        "        the denoised image.\n",
        "        Applies noise to this image, if we are not in the last step yet.\n",
        "        \"\"\"\n",
        "\n",
        "        betas_t = self.get_index_from_list(self.betas, t, x.shape)\n",
        "        sqrt_one_minus_alphas_cumprod_t = self.get_index_from_list(torch.sqrt(1. - self.alphas_cumprod), t, x.shape)\n",
        "        sqrt_recip_alphas_t = self.get_index_from_list(torch.sqrt(1.0 / self.alphas), t, x.shape)\n",
        "        mean = sqrt_recip_alphas_t * (x - betas_t * model(x, t, **kwargs)[0] / sqrt_one_minus_alphas_cumprod_t)\n",
        "        posterior_variance_t = betas_t\n",
        "\n",
        "        if t == 0:\n",
        "            return mean\n",
        "        else:\n",
        "            noise = torch.randn_like(x)\n",
        "            variance = torch.sqrt(posterior_variance_t) * noise\n",
        "            return mean + variance\n",
        "\n",
        "    @staticmethod\n",
        "    def get_index_from_list(values, t, x_shape):\n",
        "        batch_size = t.shape[0]\n",
        "        result = values.gather(-1, t.cpu())\n",
        "\n",
        "        return result.reshape(batch_size, *((1,) * (len(x_shape) - 1))).to(t.device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "czgAhD5nTPlP"
      },
      "outputs": [],
      "source": [
        "diffusion_model = DiffusionModel()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "5xDSJ0nAcgUA"
      },
      "outputs": [],
      "source": [
        "def kl_divergence(z, mu, std):\n",
        "    p = torch.distributions.Normal(torch.zeros_like(mu), torch.ones_like(std))\n",
        "    q = torch.distributions.Normal(mu, std)\n",
        "\n",
        "    log_qzx = q.log_prob(z)\n",
        "    log_pz = p.log_prob(z)\n",
        "\n",
        "    # kl\n",
        "    kl = (log_qzx - log_pz)\n",
        "    kl = kl.sum(-1)\n",
        "    return kl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "7Ki2PLQ6TRgn"
      },
      "outputs": [],
      "source": [
        "class SinusoidalPositionEmbeddings(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.dim = dim\n",
        "\n",
        "    def forward(self, time):\n",
        "        device = time.device\n",
        "        half_dim = self.dim // 2\n",
        "        embeddings = math.log(10000) / (half_dim - 1)\n",
        "        embeddings = torch.exp(torch.arange(half_dim, device=device) * -embeddings)\n",
        "        embeddings = time[:, None] * embeddings[None, :]\n",
        "        embeddings = torch.cat((embeddings.sin(), embeddings.cos()), dim=-1)\n",
        "        return embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "lrzvJVe6CTkF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "C3LVNg2bDD0X"
      },
      "outputs": [],
      "source": [
        "class Residual(nn.Module):\n",
        "    def __init__(self, fn):\n",
        "        super().__init__()\n",
        "        self.fn = fn\n",
        "\n",
        "    def forward(self, x, *args, **kwargs):\n",
        "        return self.fn(x, *args, **kwargs) + x\n",
        "\n",
        "def Upsample(dim, dim_out = None):\n",
        "    return nn.Sequential(\n",
        "        nn.Upsample(scale_factor = 2, mode = 'nearest'),\n",
        "        nn.Conv1d(dim, default(dim_out, dim), 3, padding = 1)\n",
        "    )\n",
        "\n",
        "def Downsample(dim, dim_out = None):\n",
        "    return nn.Conv1d(dim, default(dim_out, dim), 4, 2, 1)\n",
        "\n",
        "class WeightStandardizedConv2d(nn.Conv1d):\n",
        "    \"\"\"\n",
        "    https://arxiv.org/abs/1903.10520\n",
        "    weight standardization purportedly works synergistically with group normalization\n",
        "    \"\"\"\n",
        "    def forward(self, x):\n",
        "        eps = 1e-5 if x.dtype == torch.float32 else 1e-3\n",
        "\n",
        "        weight = self.weight\n",
        "        mean = reduce(weight, 'o ... -> o 1 1', 'mean')\n",
        "        var = reduce(weight, 'o ... -> o 1 1', partial(torch.var, unbiased = False))\n",
        "        normalized_weight = (weight - mean) * (var + eps).rsqrt()\n",
        "\n",
        "        return F.conv1d(x, normalized_weight, self.bias, self.stride, self.padding, self.dilation, self.groups)\n",
        "\n",
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.g = nn.Parameter(torch.ones(1, dim, 1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        eps = 1e-5 if x.dtype == torch.float32 else 1e-3\n",
        "        var = torch.var(x, dim = 1, unbiased = False, keepdim = True)\n",
        "        mean = torch.mean(x, dim = 1, keepdim = True)\n",
        "        return (x - mean) * (var + eps).rsqrt() * self.g\n",
        "\n",
        "class PreNorm(nn.Module):\n",
        "    def __init__(self, dim, fn):\n",
        "        super().__init__()\n",
        "        self.fn = fn\n",
        "        self.norm = LayerNorm(dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.norm(x)\n",
        "        return self.fn(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "FF4sj1KlBI-4"
      },
      "outputs": [],
      "source": [
        "# sinusoidal positional embeds\n",
        "\n",
        "class SinusoidalPosEmb(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.dim = dim\n",
        "\n",
        "    def forward(self, x):\n",
        "        device = x.device\n",
        "        half_dim = self.dim // 2\n",
        "        emb = math.log(10000) / (half_dim - 1)\n",
        "        emb = torch.exp(torch.arange(half_dim, device=device) * -emb)\n",
        "        emb = x[:, None] * emb[None, :]\n",
        "        emb = torch.cat((emb.sin(), emb.cos()), dim=-1)\n",
        "        return emb\n",
        "\n",
        "class RandomOrLearnedSinusoidalPosEmb(nn.Module):\n",
        "    \"\"\" following @crowsonkb 's lead with random (learned optional) sinusoidal pos emb \"\"\"\n",
        "    \"\"\" https://github.com/crowsonkb/v-diffusion-jax/blob/master/diffusion/models/danbooru_128.py#L8 \"\"\"\n",
        "\n",
        "    def __init__(self, dim, is_random = False):\n",
        "        super().__init__()\n",
        "        assert (dim % 2) == 0\n",
        "        half_dim = dim // 2\n",
        "        self.weights = nn.Parameter(torch.randn(half_dim), requires_grad = not is_random)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = rearrange(x, 'b -> b 1')\n",
        "        freqs = x * rearrange(self.weights, 'd -> 1 d') * 2 * math.pi\n",
        "        fouriered = torch.cat((freqs.sin(), freqs.cos()), dim = -1)\n",
        "        fouriered = torch.cat((x, fouriered), dim = -1)\n",
        "        return fouriered"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "pzChoL8sDKjp"
      },
      "outputs": [],
      "source": [
        "# building block modules\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, dim, dim_out, groups = 8):\n",
        "        super().__init__()\n",
        "        self.proj = WeightStandardizedConv2d(dim, dim_out, 3, padding = 1)\n",
        "        self.norm = nn.GroupNorm(groups, dim_out)\n",
        "        self.act = nn.SiLU()\n",
        "\n",
        "    def forward(self, x, scale_shift = None):\n",
        "        x = self.proj(x)\n",
        "        x = self.norm(x)\n",
        "\n",
        "        if exists(scale_shift):\n",
        "            scale, shift = scale_shift\n",
        "            x = x * (scale + 1) + shift\n",
        "\n",
        "        x = self.act(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "XESk_l-iDQ14"
      },
      "outputs": [],
      "source": [
        "class LinearAttention(nn.Module):\n",
        "    def __init__(self, dim, heads = 4, dim_head = 32):\n",
        "        super().__init__()\n",
        "        self.scale = dim_head ** -0.5\n",
        "        self.heads = heads\n",
        "        hidden_dim = dim_head * heads\n",
        "        self.to_qkv = nn.Conv1d(dim, hidden_dim * 3, 1, bias = False)\n",
        "\n",
        "        self.to_out = nn.Sequential(\n",
        "            nn.Conv1d(hidden_dim, dim, 1),\n",
        "            LayerNorm(dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, c, n = x.shape\n",
        "        qkv = self.to_qkv(x).chunk(3, dim = 1)\n",
        "        q, k, v = map(lambda t: rearrange(t, 'b (h c) n -> b h c n', h = self.heads), qkv)\n",
        "\n",
        "        q = q.softmax(dim = -2)\n",
        "        k = k.softmax(dim = -1)\n",
        "\n",
        "        q = q * self.scale\n",
        "\n",
        "        context = torch.einsum('b h d n, b h e n -> b h d e', k, v)\n",
        "\n",
        "        out = torch.einsum('b h d e, b h d n -> b h e n', context, q)\n",
        "        out = rearrange(out, 'b h c n -> b (h c) n', h = self.heads)\n",
        "        return self.to_out(out)\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, dim, heads = 4, dim_head = 32):\n",
        "        super().__init__()\n",
        "        self.scale = dim_head ** -0.5\n",
        "        self.heads = heads\n",
        "        hidden_dim = dim_head * heads\n",
        "\n",
        "        self.to_qkv = nn.Conv1d(dim, hidden_dim * 3, 1, bias = False)\n",
        "        self.to_out = nn.Conv1d(hidden_dim, dim, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, c, n = x.shape\n",
        "        qkv = self.to_qkv(x).chunk(3, dim = 1)\n",
        "        q, k, v = map(lambda t: rearrange(t, 'b (h c) n -> b h c n', h = self.heads), qkv)\n",
        "\n",
        "        q = q * self.scale\n",
        "\n",
        "        sim = einsum('b h d i, b h d j -> b h i j', q, k)\n",
        "        attn = sim.softmax(dim = -1)\n",
        "        out = einsum('b h i j, b h d j -> b h i d', attn, v)\n",
        "\n",
        "        out = rearrange(out, 'b h n d -> b (h d) n')\n",
        "        return self.to_out(out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "d8wS_-ntDgWK"
      },
      "outputs": [],
      "source": [
        "class ResnetBlock(nn.Module):\n",
        "    def __init__(self, dim, dim_out, *, time_emb_dim = None, groups = 8):\n",
        "        super().__init__()\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.SiLU(),\n",
        "            nn.Linear(time_emb_dim, dim_out * 2)\n",
        "        ) if exists(time_emb_dim) else None\n",
        "\n",
        "        self.block1 = Block(dim, dim_out, groups = groups)\n",
        "        self.block2 = Block(dim_out, dim_out, groups = groups)\n",
        "        self.res_conv = nn.Conv1d(dim, dim_out, 1) if dim != dim_out else nn.Identity()\n",
        "\n",
        "    def forward(self, x, time_emb = None):\n",
        "\n",
        "        scale_shift = None\n",
        "        if exists(self.mlp) and exists(time_emb):\n",
        "            time_emb = self.mlp(time_emb)\n",
        "            time_emb = rearrange(time_emb, 'b c -> b c 1')\n",
        "            scale_shift = time_emb.chunk(2, dim = 1)\n",
        "\n",
        "        h = self.block1(x, scale_shift = scale_shift)\n",
        "\n",
        "        h = self.block2(h)\n",
        "\n",
        "        return h + self.res_conv(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "eJaE_VvSARvJ"
      },
      "outputs": [],
      "source": [
        "# model\n",
        "class Unet1D(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        dim,\n",
        "        inp_dim,\n",
        "        init_dim = None,\n",
        "        out_dim = None,\n",
        "        dim_mults=(1, 2, 4, 8),\n",
        "        channels = 1,\n",
        "        self_condition = False,\n",
        "        resnet_block_groups = 8,\n",
        "        learned_variance = False,\n",
        "        learned_sinusoidal_cond = False,\n",
        "        random_fourier_features = False,\n",
        "        learned_sinusoidal_dim = 16\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        # determine dimensions\n",
        "\n",
        "        self.channels = channels\n",
        "        self.self_condition = self_condition\n",
        "        input_channels = channels * (2 if self_condition else 1)\n",
        "        init_dim = default(init_dim, dim)\n",
        "        self.init_conv = nn.Conv1d(input_channels, init_dim, 7, padding = 3)\n",
        "\n",
        "        dims = [init_dim, *map(lambda m: dim * m, dim_mults)]\n",
        "\n",
        "        in_out = list(zip(dims[:-1], dims[1:]))\n",
        "\n",
        "        block_klass = partial(ResnetBlock, groups = resnet_block_groups)\n",
        "\n",
        "        # time embeddings\n",
        "\n",
        "        time_dim = dim * 4\n",
        "\n",
        "        self.random_or_learned_sinusoidal_cond = learned_sinusoidal_cond or random_fourier_features\n",
        "\n",
        "        if self.random_or_learned_sinusoidal_cond:\n",
        "            sinu_pos_emb = RandomOrLearnedSinusoidalPosEmb(learned_sinusoidal_dim, random_fourier_features)\n",
        "            fourier_dim = learned_sinusoidal_dim + 1\n",
        "        else:\n",
        "            sinu_pos_emb = SinusoidalPosEmb(dim)\n",
        "            fourier_dim = dim\n",
        "\n",
        "        self.time_mlp = nn.Sequential(\n",
        "            sinu_pos_emb,\n",
        "            nn.Linear(fourier_dim, time_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(time_dim, time_dim)\n",
        "        )\n",
        "\n",
        "        # layers\n",
        "\n",
        "        self.downs = nn.ModuleList([])\n",
        "        self.ups = nn.ModuleList([])\n",
        "\n",
        "        num_resolutions = len(in_out)\n",
        "\n",
        "        for ind, (dim_in, dim_out) in enumerate(in_out):\n",
        "            is_last = ind >= (num_resolutions - 1)\n",
        "\n",
        "            self.downs.append(nn.ModuleList([\n",
        "                block_klass(dim_in, dim_in, time_emb_dim = time_dim),\n",
        "                block_klass(dim_in, dim_in, time_emb_dim = time_dim),\n",
        "                Residual(PreNorm(dim_in, LinearAttention(dim_in))),\n",
        "                Downsample(dim_in, dim_out) if not is_last else nn.Conv1d(dim_in, dim_out, 3, padding = 1)\n",
        "            ]))\n",
        "\n",
        "        mid_dim = dims[-1]\n",
        "        self.mid_block1 = block_klass(mid_dim, mid_dim, time_emb_dim = time_dim)\n",
        "        self.mid_attn = Residual(PreNorm(mid_dim, Attention(mid_dim)))\n",
        "        self.mid_block2 = block_klass(mid_dim, mid_dim, time_emb_dim = time_dim)\n",
        "\n",
        "        for ind, (dim_in, dim_out) in enumerate(reversed(in_out)):\n",
        "            is_last = ind == (len(in_out) - 1)\n",
        "\n",
        "            self.ups.append(nn.ModuleList([\n",
        "                block_klass(dim_out + dim_in, dim_out, time_emb_dim = time_dim),\n",
        "                block_klass(dim_out + dim_in, dim_out, time_emb_dim = time_dim),\n",
        "                Residual(PreNorm(dim_out, LinearAttention(dim_out))),\n",
        "                Upsample(dim_out, dim_in) if not is_last else  nn.Conv1d(dim_out, dim_in, 3, padding = 1)\n",
        "            ]))\n",
        "\n",
        "        default_out_dim = channels * (1 if not learned_variance else 2)\n",
        "        self.out_dim = default(out_dim, default_out_dim)\n",
        "\n",
        "        self.final_res_block = block_klass(dim * 2, dim, time_emb_dim = time_dim)\n",
        "        self.final_conv = nn.Conv1d(dim, self.out_dim, 1)\n",
        "\n",
        "        self.mu = nn.Linear(inp_dim, inp_dim)\n",
        "        self.var = nn.Linear(inp_dim, inp_dim)\n",
        "\n",
        "    def forward(self, x, time, x_self_cond = None):\n",
        "        if self.self_condition:\n",
        "            x_self_cond = default(x_self_cond, lambda: torch.zeros_like(x))\n",
        "            x = torch.cat((x_self_cond, x), dim = 1)\n",
        "\n",
        "        x = x.unsqueeze(1)\n",
        "        x = self.init_conv(x)\n",
        "        r = x.clone()\n",
        "        t = self.time_mlp(time)\n",
        "        h = []\n",
        "\n",
        "        for block1, block2, attn, downsample in self.downs:\n",
        "            x = block1(x, t)\n",
        "            h.append(x)\n",
        "            x = block2(x, t)\n",
        "            x = attn(x)\n",
        "            h.append(x)\n",
        "            x = downsample(x)\n",
        "\n",
        "            print('downsample',downsample)\n",
        "            print(x.shape)\n",
        "\n",
        "        x = self.mid_block1(x, t)\n",
        "        x = self.mid_attn(x)\n",
        "        x = self.mid_block2(x, t)\n",
        "\n",
        "        for block1, block2, attn, upsample in self.ups:\n",
        "\n",
        "            x = torch.cat((x, h.pop()), dim = 1)\n",
        "            x = block1(x, t)\n",
        "\n",
        "            x = torch.cat((x, h.pop()), dim = 1)\n",
        "            x = block2(x, t)\n",
        "            x = attn(x)\n",
        "\n",
        "            x = upsample(x)\n",
        "\n",
        "            print('upsample',upsample)\n",
        "\n",
        "            print(x.shape)\n",
        "\n",
        "        x = torch.cat((x, r), dim = 1)\n",
        "\n",
        "        x = self.final_res_block(x, t)\n",
        "\n",
        "        x = self.final_conv(x)\n",
        "\n",
        "        x = x.squeeze()\n",
        "\n",
        "        z_mu = self.mu(x)\n",
        "        z_var = self.var(x)\n",
        "\n",
        "        std = torch.exp(z_var / 2)\n",
        "        eps = torch.randn_like(std)\n",
        "        x_sample = eps.mul(std).add_(z_mu)\n",
        "\n",
        "        z = x_sample #torch.cat((x_sample,y), dim=1)\n",
        "\n",
        "        return z, z_mu, z_var"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "XeAUy0Qeckvp"
      },
      "outputs": [],
      "source": [
        "def plot_noise_distribution(noise, predicted_noise):\n",
        "    plt.hist(noise.cpu().numpy().flatten(), density = True, alpha = 0.8, label = \"ground truth noise\")\n",
        "    plt.hist(predicted_noise.cpu().numpy().flatten(), density = True, alpha = 0.8, label = \"predicted noise\")\n",
        "    plt.legend()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "qPXcddxbYiSo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Upsample(dim, dim_out = None):\n",
        "    return nn.Sequential(\n",
        "        nn.Upsample(scale_factor = 2, mode = 'nearest'),\n",
        "        nn.Conv1d(dim, default(dim_out, dim), 3, padding = 1)\n",
        "    )\n",
        "\n",
        "def Downsample(dim, dim_out = None):\n",
        "    return nn.Conv1d(dim, default(dim_out, dim), 4,2,1)\n",
        "\n",
        "# building block modules\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, dim, dim_out, groups = 8):\n",
        "        super().__init__()\n",
        "        self.proj = WeightStandardizedConv2d(dim, dim_out, 3, padding = 1)\n",
        "        self.norm = nn.GroupNorm(groups, dim_out)\n",
        "        self.act = nn.SiLU()\n",
        "\n",
        "    def forward(self, x, scale_shift = None):\n",
        "        x = self.proj(x)\n",
        "        x = self.norm(x)\n",
        "\n",
        "        if exists(scale_shift):\n",
        "            scale, shift = scale_shift\n",
        "            x = x * (scale + 1) + shift\n",
        "\n",
        "        x = self.act(x)\n",
        "        return x\n",
        "\n",
        "# model\n",
        "class Unet1D(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        dim,\n",
        "        inp_dim,\n",
        "        init_dim = None,\n",
        "        out_dim = None,\n",
        "        dim_mults=(1, 2, 4, 8),\n",
        "        channels = 1,\n",
        "        self_condition = False,\n",
        "        resnet_block_groups = 8,\n",
        "        learned_variance = False,\n",
        "        learned_sinusoidal_cond = False,\n",
        "        random_fourier_features = False,\n",
        "        learned_sinusoidal_dim = 16\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        # determine dimensions\n",
        "\n",
        "        self.channels = channels\n",
        "        self.self_condition = self_condition\n",
        "        input_channels = channels * (2 if self_condition else 1)\n",
        "        init_dim = default(init_dim, dim)\n",
        "        self.init_conv = nn.Conv1d(input_channels, init_dim, 7, padding = 3)\n",
        "\n",
        "        dims = [init_dim, *map(lambda m: dim * m, dim_mults)]\n",
        "        in_out = list(zip(dims[:-1], dims[1:]))\n",
        "        block_klass = partial(ResnetBlock, groups = resnet_block_groups)\n",
        "\n",
        "        # time embeddings\n",
        "\n",
        "        time_dim = dim * 4\n",
        "        self.random_or_learned_sinusoidal_cond = learned_sinusoidal_cond or random_fourier_features\n",
        "\n",
        "        if self.random_or_learned_sinusoidal_cond:\n",
        "            sinu_pos_emb = RandomOrLearnedSinusoidalPosEmb(learned_sinusoidal_dim, random_fourier_features)\n",
        "            fourier_dim = learned_sinusoidal_dim + 1\n",
        "        else:\n",
        "            sinu_pos_emb = SinusoidalPosEmb(dim)\n",
        "            fourier_dim = dim\n",
        "\n",
        "        self.time_mlp = nn.Sequential(\n",
        "            sinu_pos_emb,\n",
        "            nn.Linear(fourier_dim, time_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(time_dim, time_dim)\n",
        "        )\n",
        "\n",
        "        # layers\n",
        "\n",
        "        self.downs = nn.ModuleList([])\n",
        "        self.ups = nn.ModuleList([])\n",
        "        num_resolutions = len(in_out)\n",
        "\n",
        "\n",
        "        for ind, (dim_in, dim_out) in enumerate(in_out):\n",
        "            is_last = ind >= (num_resolutions - 1)\n",
        "            pad = 1 if ind!=0 else 2\n",
        "\n",
        "            self.downs.append(nn.ModuleList([\n",
        "                block_klass(dim_in, dim_in, time_emb_dim = time_dim),\n",
        "                block_klass(dim_in, dim_in, time_emb_dim = time_dim),\n",
        "                Downsample(dim_in, dim_out) if not is_last else nn.Conv1d(dim_in, dim_out, 3, padding = 1)\n",
        "            ]))\n",
        "\n",
        "        for ind, (dim_in, dim_out) in enumerate(reversed(in_out)):\n",
        "            is_last = ind == (len(in_out) - 1)\n",
        "            pad = 1 if ind!=3 else 0\n",
        "\n",
        "            self.ups.append(nn.ModuleList([\n",
        "                block_klass(dim_out + dim_in, dim_out, time_emb_dim = time_dim),\n",
        "                block_klass(dim_out + dim_in, dim_out, time_emb_dim = time_dim),\n",
        "                Upsample(dim_out, dim_in) if not is_last else  nn.Conv1d(dim_out, dim_in, 3, padding = 1)\n",
        "            ]))\n",
        "\n",
        "\n",
        "    def forward(self, x, time):\n",
        "\n",
        "        x = x.unsqueeze(1)\n",
        "        x = self.init_conv(x)\n",
        "        r = x.clone()\n",
        "        t = self.time_mlp(time)\n",
        "        h = []\n",
        "\n",
        "        for block1, block2, downsample in self.downs:\n",
        "            h.append(x)\n",
        "            x = block2(x, t)\n",
        "            h.append(x)\n",
        "            x = downsample(x)\n",
        "\n",
        "            print('downsample',downsample)\n",
        "            print(x.shape)\n",
        "\n",
        "        for block1, block2, upsample in self.ups:\n",
        "\n",
        "            x = torch.cat((x, h.pop()), dim = 1)\n",
        "            x = block1(x, t)\n",
        "            x = torch.cat((x, h.pop()), dim = 1)\n",
        "            x = block2(x, t)\n",
        "            x = upsample(x)\n",
        "\n",
        "            print('upsample',upsample)\n",
        "            print(x.shape)\n",
        "\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "3JvOq2-BQNM6"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pum86dLucoq6",
        "outputId": "1dca032e-80a0-4b0a-fb22-b8fd38d2314d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Unet1D(\n",
              "  (init_conv): Conv1d(1, 64, kernel_size=(7,), stride=(1,), padding=(3,))\n",
              "  (time_mlp): Sequential(\n",
              "    (0): SinusoidalPosEmb()\n",
              "    (1): Linear(in_features=64, out_features=256, bias=True)\n",
              "    (2): GELU(approximate='none')\n",
              "    (3): Linear(in_features=256, out_features=256, bias=True)\n",
              "  )\n",
              "  (downs): ModuleList(\n",
              "    (0): ModuleList(\n",
              "      (0-1): 2 x ResnetBlock(\n",
              "        (mlp): Sequential(\n",
              "          (0): SiLU()\n",
              "          (1): Linear(in_features=256, out_features=128, bias=True)\n",
              "        )\n",
              "        (block1): Block(\n",
              "          (proj): WeightStandardizedConv2d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "          (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
              "          (act): SiLU()\n",
              "        )\n",
              "        (block2): Block(\n",
              "          (proj): WeightStandardizedConv2d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "          (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
              "          (act): SiLU()\n",
              "        )\n",
              "        (res_conv): Identity()\n",
              "      )\n",
              "      (2): Conv1d(64, 64, kernel_size=(4,), stride=(2,), padding=(1,))\n",
              "    )\n",
              "    (1): ModuleList(\n",
              "      (0-1): 2 x ResnetBlock(\n",
              "        (mlp): Sequential(\n",
              "          (0): SiLU()\n",
              "          (1): Linear(in_features=256, out_features=128, bias=True)\n",
              "        )\n",
              "        (block1): Block(\n",
              "          (proj): WeightStandardizedConv2d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "          (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
              "          (act): SiLU()\n",
              "        )\n",
              "        (block2): Block(\n",
              "          (proj): WeightStandardizedConv2d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "          (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
              "          (act): SiLU()\n",
              "        )\n",
              "        (res_conv): Identity()\n",
              "      )\n",
              "      (2): Conv1d(64, 128, kernel_size=(4,), stride=(2,), padding=(1,))\n",
              "    )\n",
              "    (2): ModuleList(\n",
              "      (0-1): 2 x ResnetBlock(\n",
              "        (mlp): Sequential(\n",
              "          (0): SiLU()\n",
              "          (1): Linear(in_features=256, out_features=256, bias=True)\n",
              "        )\n",
              "        (block1): Block(\n",
              "          (proj): WeightStandardizedConv2d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "          (norm): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
              "          (act): SiLU()\n",
              "        )\n",
              "        (block2): Block(\n",
              "          (proj): WeightStandardizedConv2d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "          (norm): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
              "          (act): SiLU()\n",
              "        )\n",
              "        (res_conv): Identity()\n",
              "      )\n",
              "      (2): Conv1d(128, 256, kernel_size=(4,), stride=(2,), padding=(1,))\n",
              "    )\n",
              "    (3): ModuleList(\n",
              "      (0-1): 2 x ResnetBlock(\n",
              "        (mlp): Sequential(\n",
              "          (0): SiLU()\n",
              "          (1): Linear(in_features=256, out_features=512, bias=True)\n",
              "        )\n",
              "        (block1): Block(\n",
              "          (proj): WeightStandardizedConv2d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "          (norm): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
              "          (act): SiLU()\n",
              "        )\n",
              "        (block2): Block(\n",
              "          (proj): WeightStandardizedConv2d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "          (norm): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
              "          (act): SiLU()\n",
              "        )\n",
              "        (res_conv): Identity()\n",
              "      )\n",
              "      (2): Conv1d(256, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "    )\n",
              "  )\n",
              "  (ups): ModuleList(\n",
              "    (0): ModuleList(\n",
              "      (0-1): 2 x ResnetBlock(\n",
              "        (mlp): Sequential(\n",
              "          (0): SiLU()\n",
              "          (1): Linear(in_features=256, out_features=1024, bias=True)\n",
              "        )\n",
              "        (block1): Block(\n",
              "          (proj): WeightStandardizedConv2d(768, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "          (norm): GroupNorm(8, 512, eps=1e-05, affine=True)\n",
              "          (act): SiLU()\n",
              "        )\n",
              "        (block2): Block(\n",
              "          (proj): WeightStandardizedConv2d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "          (norm): GroupNorm(8, 512, eps=1e-05, affine=True)\n",
              "          (act): SiLU()\n",
              "        )\n",
              "        (res_conv): Conv1d(768, 512, kernel_size=(1,), stride=(1,))\n",
              "      )\n",
              "      (2): Sequential(\n",
              "        (0): Upsample(scale_factor=2.0, mode='nearest')\n",
              "        (1): Conv1d(512, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "      )\n",
              "    )\n",
              "    (1): ModuleList(\n",
              "      (0-1): 2 x ResnetBlock(\n",
              "        (mlp): Sequential(\n",
              "          (0): SiLU()\n",
              "          (1): Linear(in_features=256, out_features=512, bias=True)\n",
              "        )\n",
              "        (block1): Block(\n",
              "          (proj): WeightStandardizedConv2d(384, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "          (norm): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
              "          (act): SiLU()\n",
              "        )\n",
              "        (block2): Block(\n",
              "          (proj): WeightStandardizedConv2d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "          (norm): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
              "          (act): SiLU()\n",
              "        )\n",
              "        (res_conv): Conv1d(384, 256, kernel_size=(1,), stride=(1,))\n",
              "      )\n",
              "      (2): Sequential(\n",
              "        (0): Upsample(scale_factor=2.0, mode='nearest')\n",
              "        (1): Conv1d(256, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "      )\n",
              "    )\n",
              "    (2): ModuleList(\n",
              "      (0-1): 2 x ResnetBlock(\n",
              "        (mlp): Sequential(\n",
              "          (0): SiLU()\n",
              "          (1): Linear(in_features=256, out_features=256, bias=True)\n",
              "        )\n",
              "        (block1): Block(\n",
              "          (proj): WeightStandardizedConv2d(192, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "          (norm): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
              "          (act): SiLU()\n",
              "        )\n",
              "        (block2): Block(\n",
              "          (proj): WeightStandardizedConv2d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "          (norm): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
              "          (act): SiLU()\n",
              "        )\n",
              "        (res_conv): Conv1d(192, 128, kernel_size=(1,), stride=(1,))\n",
              "      )\n",
              "      (2): Sequential(\n",
              "        (0): Upsample(scale_factor=2.0, mode='nearest')\n",
              "        (1): Conv1d(128, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "      )\n",
              "    )\n",
              "    (3): ModuleList(\n",
              "      (0-1): 2 x ResnetBlock(\n",
              "        (mlp): Sequential(\n",
              "          (0): SiLU()\n",
              "          (1): Linear(in_features=256, out_features=128, bias=True)\n",
              "        )\n",
              "        (block1): Block(\n",
              "          (proj): WeightStandardizedConv2d(128, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "          (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
              "          (act): SiLU()\n",
              "        )\n",
              "        (block2): Block(\n",
              "          (proj): WeightStandardizedConv2d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "          (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
              "          (act): SiLU()\n",
              "        )\n",
              "        (res_conv): Conv1d(128, 64, kernel_size=(1,), stride=(1,))\n",
              "      )\n",
              "      (2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ],
      "source": [
        "BATCH_SIZE = 200\n",
        "NO_EPOCHS = 100\n",
        "PRINT_FREQUENCY = 10\n",
        "LR = 0.0001\n",
        "VERBOSE = True\n",
        "device = 'cpu'\n",
        "\n",
        "def exists(x):\n",
        "    return x is not None\n",
        "\n",
        "\n",
        "def default(val, d):\n",
        "    if exists(val):\n",
        "        return val\n",
        "    return d() if callable(d) else d\n",
        "\n",
        "unet = Unet1D(64,708)\n",
        "unet.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(unet.parameters(), lr=LR)\n",
        "\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "model = unet\n",
        "\n",
        "num_params = count_parameters(model)\n",
        "print(\"Number of parameters: {:,}\".format(num_params))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0L0vKqf-l5U",
        "outputId": "47783419-4dbd-4267-9ebf-5b0bdc29383b"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of parameters: 10,083,648\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsUkr9AlfWcT",
        "outputId": "33eed1fe-ea78-401d-c7a9-687792092139"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "200\n",
            "torch.Size([200, 704])\n",
            "torch.Size([704])\n"
          ]
        }
      ],
      "source": [
        "for test in train_loader:\n",
        "  print(len(test[0]))\n",
        "  print(test[0].shape)\n",
        "  print(test[0][0].shape)\n",
        "  break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BCQS-HPZU1S1",
        "outputId": "36c6973a-9a70-454c-cd7e-9fb4c6746120"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([200, 1, 15])\n"
          ]
        }
      ],
      "source": [
        "batch_size = 200\n",
        "input_size = 15\n",
        "kernel_size = 7\n",
        "padding = 3\n",
        "output_size = 1  # Desired number of output channels\n",
        "\n",
        "# Reshape the input data to have a channel dimension of 1\n",
        "input_data = torch.randn(batch_size, 1, input_size)\n",
        "\n",
        "# Define the convolutional layer\n",
        "conv_layer = nn.Conv1d(1, output_size, kernel_size, padding=padding)\n",
        "\n",
        "# Apply the convolutional layer to the input data\n",
        "output = conv_layer(input_data)\n",
        "\n",
        "print(output.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 687
        },
        "id": "xs0rkaguc8Hv",
        "outputId": "298ac338-3de8-4b56-a161-74d1f8d76d31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "downsample Conv1d(64, 64, kernel_size=(4,), stride=(2,), padding=(1,))\n",
            "torch.Size([200, 64, 352])\n",
            "downsample Conv1d(64, 128, kernel_size=(4,), stride=(2,), padding=(1,))\n",
            "torch.Size([200, 128, 176])\n",
            "downsample Conv1d(128, 256, kernel_size=(4,), stride=(2,), padding=(1,))\n",
            "torch.Size([200, 256, 88])\n",
            "downsample Conv1d(256, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
            "torch.Size([200, 512, 88])\n",
            "upsample Sequential(\n",
            "  (0): Upsample(scale_factor=2.0, mode='nearest')\n",
            "  (1): Conv1d(512, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
            ")\n",
            "torch.Size([200, 256, 176])\n",
            "upsample Sequential(\n",
            "  (0): Upsample(scale_factor=2.0, mode='nearest')\n",
            "  (1): Conv1d(256, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
            ")\n",
            "torch.Size([200, 128, 352])\n",
            "upsample Sequential(\n",
            "  (0): Upsample(scale_factor=2.0, mode='nearest')\n",
            "  (1): Conv1d(128, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
            ")\n",
            "torch.Size([200, 64, 704])\n",
            "upsample Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
            "torch.Size([200, 64, 704])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-84-daab6b8d333a>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_noisy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mpredicted_noise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'z' is not defined"
          ]
        }
      ],
      "source": [
        "for epoch in range(100):\n",
        "\n",
        "    mean_epoch_loss = []\n",
        "    mean_epoch_loss_val = []\n",
        "    for batch in train_loader:\n",
        "\n",
        "        batch = batch[0]\n",
        "\n",
        "        t = torch.randint(0, diffusion_model.timesteps, (BATCH_SIZE,)).long().to(device)\n",
        "        try:\n",
        "          batch_noisy, noise = diffusion_model.forward(batch, t, device)\n",
        "        except:\n",
        "          continue\n",
        "\n",
        "        #z , z_mu, z_var = unet(batch_noisy, t)\n",
        "        x = unet(batch_noisy, t)\n",
        "\n",
        "        predicted_noise = z\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        kld = torch.mean(-0.5 * torch.sum(1 + z_var - z_mu ** 2 - z_var.exp(), dim = 1), dim = 0)\n",
        "        loss = kld #kl_divergence(z , z_mu, z_var) #torch.nn.functional.mse_loss(noise, predicted_noise)\n",
        "        mean_epoch_loss.append(loss.item())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    for batch in test_loader:\n",
        "\n",
        "        batch = batch[0]\n",
        "\n",
        "        t = torch.randint(0, diffusion_model.timesteps, (BATCH_SIZE,)).long().to(device)\n",
        "\n",
        "        batch_noisy, noise = diffusion_model.forward(batch, t, device)\n",
        "\n",
        "        z , z_mu, z_var = unet(batch_noisy, t)\n",
        "\n",
        "        predicted_noise = z\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        kld = torch.mean(-0.5 * torch.sum(1 + z_var - z_mu ** 2 - z_var.exp(), dim = 1), dim = 0)\n",
        "        loss = kld #kl_divergence(z , z_mu, z_var) #torch.nn.functional.mse_loss(noise, predicted_noise)\n",
        "        mean_epoch_loss_val.append(loss.item())\n",
        "\n",
        "    if epoch % PRINT_FREQUENCY == 0:\n",
        "        print('---')\n",
        "        print(f\"Epoch: {epoch} | Train Loss {np.mean(mean_epoch_loss)} | Val Loss {np.mean(mean_epoch_loss_val)}\")\n",
        "        if VERBOSE:\n",
        "            with torch.no_grad():\n",
        "                plot_noise_distribution(noise, predicted_noise)\n",
        "\n",
        "        torch.save(unet.state_dict(), f\"epoch: {epoch}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ss3VqLvxmqmh"
      },
      "outputs": [],
      "source": [
        "diffusion_model.timesteps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-8CsVvwXmhwq"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "    img = torch.randn(1,15).to(device)\n",
        "    for i in reversed(range(diffusion_model.timesteps)):\n",
        "        t = torch.full((1,), i, dtype=torch.long, device=device)\n",
        "        img = diffusion_model.backward(img, t, unet.eval())\n",
        "        if i % 50 == 0:\n",
        "            print('i',i)\n",
        "            print(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S75-PGcru0Hi"
      },
      "outputs": [],
      "source": [
        "import ase\n",
        "import yaml\n",
        "import time\n",
        "import copy\n",
        "import joblib\n",
        "import pickle\n",
        "import numpy as np\n",
        "import datetime\n",
        "from ase import Atoms, io, build\n",
        "\n",
        "data_list = []\n",
        "n_samples = 20\n",
        "\n",
        "i = 1\n",
        "m = 0\n",
        "\n",
        "print('a')\n",
        "\n",
        "while len(data_list) < n_samples :\n",
        "\n",
        "    rev_x = 0\n",
        "    rev_x_need_scaling, composition_vec = rev_x[:, :708-101], rev_x[:,-101:]\n",
        "\n",
        "    rev_x_scaled = scaler.inverse_transform(rev_x_need_scaling.cpu().data.numpy())\n",
        "    rev_x_scaled = torch.tensor(rev_x_scaled, dtype=torch.float, device='cpu')\n",
        "\n",
        "    tota_atm = torch.round(composition_vec[:,100])\n",
        "    composition_vec = composition_vec[:,0:100]\n",
        "\n",
        "    top_values, top_indices = composition_vec.topk(6)\n",
        "    new_tensor2 = torch.zeros_like(composition_vec)\n",
        "    new_tensor2[0][top_indices] = top_values\n",
        "\n",
        "    composition_vec = (torch.round(new_tensor2[0]))\n",
        "    composition_vec[composition_vec < 0] = 0 # May change this value.\n",
        "    sum_comp = torch.sum(composition_vec[0])\n",
        "\n",
        "    atomic_vec = torch.round((composition_vec/5) * tota_atm).int()\n",
        "    atomic_vec = atomic_vec.flatten()\n",
        "\n",
        "\n",
        "    if torch.sum(atomic_vec) == 0:# or (torch.any(cell > 3)):\n",
        "      continue\n",
        "\n",
        "    atomic_numbers = []\n",
        "\n",
        "    # find atomic number of all the elements with non-zero compostions.\n",
        "\n",
        "    # atomic number will be as a tensor.\n",
        "    for j in range(100):\n",
        "        atomic_numbers.append(atomic_vec[j]*[str(j+1)])\n",
        "\n",
        "    # make list of lists. [[] , [] , []]\n",
        "    atomic_numbers = [item for sublist in atomic_numbers for item in sublist]\n",
        "\n",
        "    if len(atomic_numbers)!=5: # or (tota_atm<5):\n",
        "      continue\n",
        "\n",
        "\n",
        "    cell = rev_x_scaled[0, 601:607]\n",
        "\n",
        "    print(\"cell1: \", cell)  # cell1:  tensor([3.8627, 4.6770, 6.7244, 1.5247, 1.7004, 1.5864])\n",
        "    cell[3:6] = cell[3:6] * 180 / np.pi\n",
        "    print(\"cell2: \", cell)  #cell2:  tensor([ 3.8627,  4.6770,  6.7244, 87.3581, 97.4244, 90.8916])\n",
        "\n",
        "    print(\"========= \", i)\n",
        "    print('dist',rev_x_scaled[0][600])\n",
        "    print('composition_vec',composition_vec)\n",
        "    print('atomic_vec',atomic_vec)\n",
        "    print('tot_atm', tota_atm)\n",
        "    print('atomic_num', atomic_numbers)\n",
        "    print(\"cell1: \", cell)\n",
        "\n",
        "    placeholder = Atoms(numbers=[1], positions=[[0,0,0]], cell=cell.detach().cpu().numpy())\n",
        "    cell = placeholder.get_cell()\n",
        "\n",
        "    # fianl data dictionary\n",
        "    data = {}\n",
        "    data['positions'] = []\n",
        "    data['atomic_numbers'] = np.array(atomic_numbers, dtype=\"int\")\n",
        "    data['cell'] = torch.tensor(np.array(cell), dtype=torch.float, device='cpu')\n",
        "    data['representation'] = torch.unsqueeze(rev_x_scaled[0,:708-101-6], 0).detach()\n",
        "\n",
        "\n",
        "    i+=1\n",
        "    data_list.append(data)\n",
        "    print('done')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QqzZPTBidAcT"
      },
      "outputs": [],
      "source": [
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lqwuKf5AjLNX"
      },
      "outputs": [],
      "source": [
        "NUM_CLASSES = len(classes)\n",
        "NUM_DISPLAY_IMAGES = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j1FPehGgjNx7"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(16)\n",
        "\n",
        "plt.figure(figsize=(15,15))\n",
        "f, ax = plt.subplots(NUM_CLASSES, NUM_DISPLAY_IMAGES, figsize = (100,100))\n",
        "\n",
        "for c in range(NUM_CLASSES):\n",
        "    imgs = torch.randn((NUM_DISPLAY_IMAGES, 3) + IMAGE_SHAPE).to(device)\n",
        "    for i in reversed(range(diffusion_model.timesteps)):\n",
        "        t = torch.full((1,), i, dtype=torch.long, device=device)\n",
        "        labels = torch.tensor([c] * NUM_DISPLAY_IMAGES).resize(NUM_DISPLAY_IMAGES, 1).float().to(device)\n",
        "        imgs = diffusion_model.backward(x=imgs, t=t, model=unet.eval().to(device), labels = labels)\n",
        "    for idx, img in enumerate(imgs):\n",
        "        ax[c][idx].imshow(reverse_transform(img))\n",
        "        ax[c][idx].set_title(f\"Class: {classes[c]}\", fontsize = 100)\n",
        "\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}